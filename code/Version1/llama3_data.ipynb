{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "818eb425",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import re\n",
    "from docx import Document\n",
    "from docx.shared import Pt\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "53e79d7f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_from_word(docx_path):\n",
    "    \"\"\"\n",
    "    Extracts apartment information from a Word file based on font size constraints and specific Regex patterns, while excluding underlined text from descriptions.\n",
    "    \"\"\"\n",
    "    doc = Document(docx_path)\n",
    "    \n",
    "    apartments = []\n",
    "    current_apt = {}\n",
    "    current_desc_parts = []\n",
    "    \n",
    "    #Flag to track if we just found a title and need the address next\n",
    "    waiting_for_address = False\n",
    "    \n",
    "    # Regex to ensure that the apartment name starts with \"Splendom\" (case insensitive)\n",
    "    title_pattern = re.compile(r'(?i)^splendom.*')\n",
    "\n",
    "    for para in doc.paragraphs:\n",
    "        #To detect if the paragraph is a title, Regex is used along with font size check (16pt+).\n",
    "        \n",
    "        is_title_size = False\n",
    "        max_size = 0\n",
    "        \n",
    "        for run in para.runs:\n",
    "            if run.font.size:\n",
    "                if run.font.size.pt > max_size:\n",
    "                    max_size = run.font.size.pt\n",
    "        \n",
    "        if max_size >= 16:\n",
    "            is_title_size = True\n",
    "\n",
    "        #Clean text for Regex check\n",
    "        clean_text = para.text.strip()\n",
    "        \n",
    "        #Regex AND font size greater than 16.\n",
    "        if is_title_size and title_pattern.match(clean_text):\n",
    "            #Save previous apartment if exists.\n",
    "            if current_apt:\n",
    "                current_apt[\"description\"] = \"\".join(current_desc_parts).strip()\n",
    "                apartments.append(current_apt)\n",
    "            \n",
    "            # Apartment structure\n",
    "            current_apt = {\n",
    "                \"name\": clean_text,\n",
    "                \"description\": \"\",\n",
    "                \"lat\": None,\n",
    "                \"lon\": None,\n",
    "                \"geocoded_address\": \"\",\n",
    "                \"Country\": \"Pending Excel Merge\",\n",
    "                \"City\": \"Pending Excel Merge\",\n",
    "                \"url\": \"\",\n",
    "                \"supplier link\": \"\",\n",
    "                \"email\": \"\",\n",
    "                \"phone\": \"\"\n",
    "            }\n",
    "            current_desc_parts = []\n",
    "            \n",
    "            #We found a title, so the NEXT paragraph should be the address.\n",
    "            waiting_for_address = True\n",
    "            \n",
    "        else:\n",
    "            #If it's not an apartment title, we check if it is an address or description.\n",
    "            if current_apt:\n",
    "                if waiting_for_address:\n",
    "                    #If the line is not empty, we assume it is the address\n",
    "                    if clean_text:\n",
    "                        current_apt[\"geocoded_address\"] = clean_text\n",
    "                        waiting_for_address = False\n",
    "                \n",
    "                else:\n",
    "                    #If we already have the address, then it's a description.\n",
    "                    for run in para.runs:\n",
    "                        #Only add to the description the text is NOT underlined.\n",
    "                        if not run.font.underline: \n",
    "                            current_desc_parts.append(run.text)\n",
    "                    \n",
    "                    current_desc_parts.append(\"\\n\")\n",
    "\n",
    "    if current_apt:\n",
    "        current_apt[\"description\"] = \"\".join(current_desc_parts).strip()\n",
    "        apartments.append(current_apt)\n",
    "        \n",
    "    return apartments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "d3adcf2b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_from_excel(excel_path, apartments_data):\n",
    "    \"\"\"\n",
    "    Reads an Excel file and merges its data with the apartments JSON structure.\n",
    "    \n",
    "    Expected Excel columns:\n",
    "    - Apartment Name\n",
    "    - Splendom Link (maps to 'url')\n",
    "    - Supplier Link (maps to 'supplier link')\n",
    "    - Email\n",
    "    - Phone\n",
    "    \"\"\"\n",
    "    \n",
    "    #Read the Excel file\n",
    "    df = pd.read_excel(excel_path)\n",
    "        \n",
    "    #Create a dictionary mapping apartment names to Excel row data.\n",
    "    excel_data = {}\n",
    "    for idx, row in df.iterrows():\n",
    "        apt_name = row['Apartment Name'].strip().lower()\n",
    "        excel_data[apt_name] = {\n",
    "            'url': row['Splendom Link'],\n",
    "            'supplier link': row['Supplier Link'],\n",
    "            'email': row['Email'],\n",
    "            'phone': str(row['Phone'])\n",
    "        }\n",
    "        \n",
    "    #Merge Excel data with apartments data\n",
    "    for apt in apartments_data:\n",
    "        apt_name = apt['name'].strip().lower()\n",
    "        \n",
    "        #Find a matching apartment in the Excel data\n",
    "        if apt_name in excel_data:\n",
    "            excel_row = excel_data[apt_name]\n",
    "            apt['url'] = excel_row['url']\n",
    "            apt['supplier link'] = excel_row['supplier link']\n",
    "            apt['email'] = excel_row['email']\n",
    "            apt['phone'] = excel_row['phone']\n",
    "        else:\n",
    "            print(f\"No matching apartment.\")\n",
    "        \n",
    "    return apartments_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "4e2df775",
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_to_json(word_path, excel_path, json_output_path):\n",
    "    \"\"\"\n",
    "    Main function to extract data from Word and Excel files and save to a JSON file.\n",
    "    \"\"\"\n",
    "    #1. Extract from Word.\n",
    "    data = extract_from_word(word_path)\n",
    "    \n",
    "    #2. Extract from Excel.\n",
    "    data = extract_from_excel(excel_path, data)\n",
    "    \n",
    "    #3. Save to JSON\n",
    "    with open(json_output_path, 'w', encoding='utf-8') as f:\n",
    "        json.dump(data, f, ensure_ascii=False, indent=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "70dce31e",
   "metadata": {},
   "outputs": [],
   "source": [
    "save_to_json(\"dummy_word.docx\", \"dummy_excel.xlsx\", \"dummy_corpus.json\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "nlp",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
