{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "4743c901",
   "metadata": {},
   "source": [
    "## Dummy Dataset Generation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "63d2e65e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import time\n",
    "import random\n",
    "import os\n",
    "from pathlib import Path\n",
    "from groq import Groq\n",
    "import re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f8f8c16c",
   "metadata": {},
   "outputs": [],
   "source": [
    "client = Groq(api_key=\"dummy_key_for_demo\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c5afbf4d",
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "Dummy data generation for NLU training in real estate chatbot context.\n",
    "'''\n",
    "\n",
    "CLEAN_LOCATIONS = [\n",
    "    \"Baker Street 221B, 12345 London, UK\",\n",
    "    \"Paris\",\n",
    "    \"Nueva España, Madrid\",\n",
    "    \"Gran Vía 10, 28013 Madrid, Spain\",\n",
    "    \"Milan\",\n",
    "    \"Fifth Avenue 725, 10022 New York, USA\",\n",
    "    \"Rua Augusta 20, 1100-053 Lisbon, Portugal\",\n",
    "    \"Kärntner Straße 15, 1010 Vienna, Austria\"\n",
    "]\n",
    "\n",
    "AMENITY_SYNONYMS = {\n",
    "        'AIR_CONDITIONING': ['air conditioning', 'ac', 'a/c', 'climate control', 'cooling'],\n",
    "        'BALCONY': ['balcony', 'outdoor space', 'private terrace'],\n",
    "        'COFFEE_MACHINE': ['coffee machine', 'nespresso', 'espresso maker'],\n",
    "        'FITNESS_CENTER': ['fitness center', 'gym', 'workout room', 'weights'],\n",
    "        'INTERNET': ['internet', 'wifi', 'wi-fi', 'high-speed connection'],\n",
    "        'KITCHEN': ['kitchen', 'fully equipped kitchen', 'kitchenette'],\n",
    "        'PET_POLICY': ['pet friendly', 'pets allowed', 'dog friendly', 'cat friendly'],\n",
    "        'POOL': ['pool', 'swimming pool', 'rooftop pool'],\n",
    "        'SMART_TV': ['smart tv', 'netflix', 'streaming apps', 'hbo'],\n",
    "        'WORK_DESK': ['work desk', 'home office', 'monitor setup', 'working area'],\n",
    "        'WASHING_MACHINE': ['washer', 'laundry machine', 'washing machine'],\n",
    "        \n",
    "        'STUDIO': ['studio', 'studio apartment', 'loft'],\n",
    "        'ONE_BEDROOM': ['1 bedroom', 'one bedroom', '1-bed'],\n",
    "        'TWO_BEDROOM': ['2 bedroom', 'two bedroom', '2-bed'],\n",
    "        'THREE_BEDROOM': ['3 bedroom', 'three bedroom', 'family apartment']\n",
    "}\n",
    "\n",
    "REAL_APARTMENTS = [\n",
    "    \"SPLENDOM Downtown\", \n",
    "    \"SPLENDOM Central Park\", \n",
    "    \"SPLENDOM Riverside\", \n",
    "    \"SPLENDOM Financial District\",\n",
    "    \"SPLENDOM Old Town\",\n",
    "    \"SPLENDOM Harbor View\",\n",
    "    \"SPLENDOM University\",\n",
    "    \"SPLENDOM West End\",\n",
    "    \"SPLENDOM Opera\",\n",
    "    \"SPLENDOM Market Square\"\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fcca039e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_random_synonyms(count=6):\n",
    "    \"\"\"\n",
    "    Selects random amenities and their synonyms to diversify training vocabulary.\n",
    "    \"\"\"\n",
    "    keys = random.sample(list(AMENITY_SYNONYMS.keys()), k=min(count, len(AMENITY_SYNONYMS)))\n",
    "    flat_list = []\n",
    "    for k in keys:\n",
    "        flat_list.append(random.choice(AMENITY_SYNONYMS[k]))\n",
    "    return flat_list\n",
    "\n",
    "def get_random_apartments(count=4):\n",
    "    \"\"\"\n",
    "    Simulate noise in apartment names by randomly altering the casing of \"SPLENDOM\" in some names.\n",
    "    \"\"\"\n",
    "    raw_names = random.sample(REAL_APARTMENTS, k=min(count, len(REAL_APARTMENTS)))\n",
    "    processed = []\n",
    "    for name in raw_names:\n",
    "        if random.random() < 0.2 and \"SPLENDOM\" in name:\n",
    "            variation = random.choice([\"splendom\", \"Splendom\", \"Splenom\"]) \n",
    "            name = name.replace(\"SPLENDOM\", variation)\n",
    "        processed.append(name)\n",
    "    return processed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "07e17df2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_nlu_samples(intent_type, count=50):\n",
    "#Generate noise and diversity in training data.    \n",
    "    current_synonyms = get_random_synonyms(count=6)\n",
    "    current_apartments = get_random_apartments(count=3)\n",
    "    \n",
    "    # Select random locations directly from the clean list\n",
    "    current_locations = random.sample(CLEAN_LOCATIONS, k=min(5, len(CLEAN_LOCATIONS)))\n",
    "    \n",
    "    fake_amenities = [\"underwater room\", \"gold toilet\", \"butler named James\"]\n",
    "\n",
    "    #System prompts based on intent type\n",
    "    if intent_type == \"DISCOVERY\":\n",
    "        system_msg = f\"\"\"\n",
    "        Generate synthetic user queries for a real estate chatbot.\n",
    "        Intent: DISCOVERY (User wants to find an apartment by CRITERIA).\n",
    "        \n",
    "        INSTRUCTIONS:\n",
    "        1. Use ENGLISH syntax but preserve location names exactly as provided.\n",
    "        2. Inject these LOCATIONS: {', '.join(current_locations)}.\n",
    "        3. Inject these AMENITIES: {', '.join(current_synonyms)}.\n",
    "        4. Queries should look like: \"flat near [LOCATION] with [AMENITY]\", \"studio in [LOCATION]\".\n",
    "        \"\"\"\n",
    "        \n",
    "    elif intent_type == \"DETAILS\":\n",
    "        system_msg = f\"\"\"\n",
    "        Generate synthetic user queries for a real estate chatbot.\n",
    "        Intent: DETAILS (User asks specific info about a NAMED apartment).\n",
    "        \n",
    "        INSTRUCTIONS:\n",
    "        1. Queries MUST include one of these identifiers: {', '.join(current_apartments)}.\n",
    "        2. Ask about policies: \"Does [NAME] allow pets?\", \"check-in for [NAME]\".\n",
    "        \"\"\"\n",
    "\n",
    "    elif intent_type == \"OTHER\":\n",
    "        system_msg = f\"\"\"\n",
    "        Intent: OTHER (Out of Domain).\n",
    "        Generate queries the bot should ignore:\n",
    "        1. Greetings (\"Hello\").\n",
    "        2. Off-topic (\"How is the weather?\").\n",
    "        3. Impossible requests: {', '.join(fake_amenities)}.\n",
    "        \"\"\"\n",
    "\n",
    "    prompt = f\"\"\"\n",
    "    Generate {count} unique training examples.\n",
    "    Output strictly a JSON list of objects: [{{\"text\": \"query...\", \"label\": \"{intent_type}\"}}, ...]\n",
    "    \"\"\"\n",
    "    \n",
    "    try:\n",
    "        #API call to Llama3\n",
    "        completion = client.chat.completions.create(\n",
    "            messages=[\n",
    "                {\"role\": \"system\", \"content\": system_msg},\n",
    "                {\"role\": \"user\", \"content\": prompt}\n",
    "            ],\n",
    "            model=\"llama-3.3-70b-versatile\",\n",
    "            temperature=0.85, \n",
    "            response_format={\"type\": \"json_object\"}\n",
    "        )\n",
    "        content = completion.choices[0].message.content\n",
    "        \n",
    "        data = json.loads(content)\n",
    "        \n",
    "        if isinstance(data, list): \n",
    "            return data\n",
    "        if isinstance(data, dict): \n",
    "            for k in data: \n",
    "                if isinstance(data[k], list): \n",
    "                    return data[k]\n",
    "        return []\n",
    "            \n",
    "    except Exception as e:\n",
    "        print(f\"Error during API call: {e}\")\n",
    "        return []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ed9a4805",
   "metadata": {},
   "outputs": [],
   "source": [
    "OUTPUT_FILE = \"data/nlu_dummy_dataset.json\"\n",
    "TARGET_SAMPLES_PER_INTENT = 20 #In production this is set to thousands \n",
    "    \n",
    "Path(\"data\").mkdir(exist_ok=True)\n",
    "all_data = []\n",
    "intent_list = [\"DISCOVERY\", \"DETAILS\", \"OTHER\"]\n",
    "\n",
    "for intent in intent_list:\n",
    "    print(f\"\\nGenerating samples for Intent: {intent}...\")\n",
    "    current_count = 0\n",
    "    while current_count < TARGET_SAMPLES_PER_INTENT:\n",
    "        batch = generate_nlu_samples(intent, count=50) \n",
    "        if not batch:\n",
    "            time.sleep(1)\n",
    "            continue\n",
    "        \n",
    "        all_data.extend(batch)\n",
    "        current_count += len(batch)\n",
    "        time.sleep(0.5)\n",
    "\n",
    "#Save results\n",
    "random.shuffle(all_data) \n",
    "        \n",
    "with open(OUTPUT_FILE, 'w', encoding='utf-8') as f:\n",
    "    json.dump(all_data, f, indent=2, ensure_ascii=False)\n",
    "print(f\"\\nGeneration completed with {len(all_data)} samples to {OUTPUT_FILE}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "nlp",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
